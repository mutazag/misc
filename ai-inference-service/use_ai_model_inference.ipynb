{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider, AzureCliCredential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"DeepSeek-R1\": \"DeepSeek-R1\",\n",
    "    \"Phi-4-mini-instruct\": \"Phi-4-mini-instruct\",\n",
    "    \"gpt-4o\": \"gpt-4o\",\n",
    "    \"o3-mini\": \"o3-mini\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT_KEY\")),\n",
    "    credential_scopes=[\"https://cognitiveservices.azure.com/.default\"],\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_think_tags(content):\n",
    "    \"\"\"\n",
    "    Parse the <think> </think> tags out of the response in content\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Find all <think>...</think> tags and their content\n",
    "    think_tags = re.findall(r\"<think>(.*?)</think>\", content)\n",
    "    # match = re.search(r\"<think>(.*?)</think>\", content)\n",
    "    # think_tags = match.group(0) if match else \"\"\n",
    "\n",
    "    # Remove the <think>...</think> tags from the content\n",
    "    content_without_think_tags = re.sub(r\"<think>.*?</think>\", \"\", content)\n",
    "\n",
    "    return think_tags, content_without_think_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    UserMessage(content=\"1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek-R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.complete(\n",
    "    messages = messages,\n",
    "    model = models['DeepSeek-R1']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the problem is: \"1 shirt needs 1 hour to dry. How long does it take to dry 3 shirts?\" Hmm, at first glance, this seems straightforward, but maybe there's a trick here. Let me think through it step by step.\n",
      "\n",
      "First, the basic idea. If one shirt takes 1 hour to dry when it's by itself, what happens when there are three shirts? Does drying time increase with more shirts, or does it stay the same? Well, if they're all drying simultaneously, like hanging next to each other on a clothesline or in a dryer, they might all dry at the same time. So maybe the answer is still 1 hour because they can all dry together. But wait, maybe there's a condition where drying multiple shirts could interfere with each other. Let me consider different scenarios.\n",
      "\n",
      "Scenario 1: Drying outdoors on a line. If you hang three shirts next to each other, they all get exposed to the same sunlight and air. Unless they're so close that they block each other's airflow, they should dry in the same amount of time as one shirt. So, 1 hour.\n",
      "\n",
      "Scenario 2: Using a clothes dryer. If you put one shirt in the dryer, it takes 1 hour. But if you put three shirts in, does that affect the drying time? Maybe. In real life, stuffing too many clothes in a dryer can make them take longer because the hot air can't circulate properly. But the problem doesn't mention a dryer or any limitations on space. It just says \"1 shirt needs 1 hour to dry.\" Maybe we're to assume ideal conditions where adding more shirts doesn't affect the drying time. If that's the case, then three shirts would also take 1 hour.\n",
      "\n",
      "But maybe the question is trying to trick us into thinking it's 3 hours by assuming each shirt requires 1 hour individually and you have to add them up. But that doesn't make sense because drying is usually a process that can be done in parallel. Unless you can only dry one shirt at a time for some reason, which seems unlikely. The problem doesn't specify any constraints like that. So if you can dry all three simultaneously, it's still 1 hour.\n",
      "\n",
      "Wait, let me check for similar problems. For example, if one pizza takes 10 minutes in the oven, how long for three pizzas? If the oven can fit all three, it's still 10 minutes. But if the oven can only fit one at a time, then it's 30 minutes. So maybe the answer depends on whether the drying process is parallel or sequential. The problem here doesn't specify, so perhaps we need to make an assumption.\n",
      "\n",
      "But the problem says \"1 shirt needs 1 hour to dry.\" It doesn't mention anything about the method or capacity. So maybe we are to assume that drying multiple shirts doesn't interfere. Therefore, three shirts would also take 1 hour. Alternatively, maybe the answer is different. Let me see.\n",
      "\n",
      "Alternatively, maybe it's a trick question where each shirt requires the total time. But I don't think so. Unless there's something about the drying process where each shirt adds to the time. But in reality, unless there's some sort of resource constraint, more shirts don't take longer. For example, if you have a dehumidifier and the drying process is dependent on removing moisture from the air, but that's probably overcomplicating it.\n",
      "\n",
      "The problem is likely testing the understanding of parallel vs. sequential tasks. If drying one shirt takes an hour, then drying three shirts in parallel (at the same time) still takes an hour. If you have to dry them one after another (sequentially), then it would take three hours. But since the problem doesn't specify that you can only dry one at a time, the answer is probably 1 hour.\n",
      "\n",
      "So, unless the question is trying to get you to consider sequential drying, but that seems like an assumption. Without more information, the safest answer is 1 hour.\n",
      "\n",
      "Wait, but maybe there's another angle. If by \"dry\" they mean the total time each shirt is drying, like in terms of man-hours. For example, 1 shirt takes 1 hour, so 3 shirts would take 3 hours total, but if they are dried at the same time, that's 1 hour. So the total time is 1 hour, but the total effort is 3 hours. But the question is asking for how long does it take to dry them, not the total hours. So yeah, it's 1 hour.\n",
      "\n",
      "I think the answer is 1 hour. Because all three can dry simultaneously. The key point is that drying time is not additive unless they have to be done in sequence. Since the problem doesn't specify any limitations on drying multiple shirts at once, the answer should be 1 hour.\n",
      "</think>\n",
      "\n",
      "The time required to dry 3 shirts remains **1 hour**, assuming they are dried simultaneously under the same conditions. Since drying can typically be done in parallel (e.g., hanging multiple shirts on a line or using a dryer with sufficient space), the number of shirts does not increase the drying time unless specified otherwise. Each shirt dries independently, so all three will be dry in the same 1-hour period. \n",
      "\n",
      "**Answer:** 1 hour.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes **1 hour** to dry 3 shirts, assuming all the shirts are drying at the same time under the same conditions (e.g., hung up together). The drying time is not additive; it depends on the drying process, which treats all shirts simultaneously rather than sequentially.\n"
     ]
    }
   ],
   "source": [
    "# gpt-4o\n",
    "response = client.complete(\n",
    "    messages = messages,\n",
    "    model = models[\"gpt-4o\"]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi-4-mini-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If 1 shirt needs 1 hour to dry, then 3 shirts would also take 1 hour to dry, assuming they are placed close enough together to share the same drying space and the drying conditions (like airflow) remain constant. However, if they are separated and require individual space to dry, then it would take 3 hours for 3 shirts to dry.\n"
     ]
    }
   ],
   "source": [
    "response = client.complete(\n",
    "    messages = messages,\n",
    "    model = models['Phi-4-mini-instruct']\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": messages[0].content\n",
    "            }\n",
    "        ]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = aoai_client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=messages,\n",
    "    max_completion_tokens=100000,\n",
    "    stop=None,\n",
    "    stream=False ,\n",
    "\n",
    "    reasoning_effort=\"high\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the shirts are dried at the same time (for example, hung on a clothesline or placed in a dryer that can handle multiple shirts), then it takes 1 hour to dry all three shirts, because they dry simultaneously rather than one after the other.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BBcaOeIpUQaAKHdVsSXKHYS3UiN5a\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"If the shirts are dried at the same time (for example, hung on a clothesline or placed in a dryer that can handle multiple shirts), then it takes 1 hour to dry all three shirts, because they dry simultaneously rather than one after the other.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1742109632,\n",
      "  \"model\": \"o3-mini-2025-01-31\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_ded0d14823\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1101,\n",
      "    \"prompt_tokens\": 26,\n",
      "    \"total_tokens\": 1127,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 1024,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
