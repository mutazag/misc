{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider, AzureCliCredential\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    ToolMessage,\n",
    "    AssistantMessage\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "endpoint = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT\")\n",
    "model_name  = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "project_connect = os.getenv(\"AZURE_AI_PROJECT_CONN_STR\")\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT_KEY\")),\n",
    "    # credential=DefaultAzureCredential(),\n",
    "    credential_scopes=[\"https://cognitiveservices.azure.com/.default\"],\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "messages = [\n",
    "    UserMessage(content=\"1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "import sys\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    conn_str=project_connect,\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "project_client.telemetry.get_connection_string()\n",
    "project_client.telemetry.enable(destination=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\n",
      "If shirts are being dried under the same conditions and at the same time, **3 shirts will still take 1 hour to dry**â€”not more. Drying time doesnâ€™t accumulate based on the number of shirts being dried simultaneously, as long as the drying process can accommodate them all at once.\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)\n",
    "\n",
    "try:\n",
    "    response = client.complete(\n",
    "        messages = messages,\n",
    "        model = model_name,\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from opentelemetry import trace\n",
    "\n",
    "# Install opentelemetry with command \"pip install opentelemetry-sdk\".\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage, CompletionsFinishReason\n",
    "from azure.core.credentials import AzureKeyCredential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START trace_setting]\n",
    "from azure.core.settings import settings\n",
    "\n",
    "settings.tracing_implementation = \"opentelemetry\"\n",
    "# [END trace_setting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client.telemetry.get_connection_string()\n",
    "project_client.telemetry.enable(destination=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/inference/sample_chat_completions_with_azure_openai_client_and_azure_monitor_tracing.py\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    print(\"Application Insights was not enabled for this project.\")\n",
    "    print(\"Enable it via the 'Tracing' tab in your AI Foundry project page.\")\n",
    "    exit()\n",
    "\n",
    "# Enable additional instrumentations for openai and langchain\n",
    "# which are not included by Azure Monitor out of the box\n",
    "project_client.telemetry.enable()\n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are **5,280 feet** in a mile.\n"
     ]
    }
   ],
   "source": [
    "with project_client.inference.get_azure_openai_client(api_version=\"2024-06-01\") as client:\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How many feet are in a mile?\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! ðŸ˜Š How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "with project_client.inference.get_chat_completions_client() as client:\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello there\",\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    # print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ConnectionType.AZURE_OPEN_AI: 'AzureOpenAI'>,\n",
       " <ConnectionType.SERVERLESS: 'Serverless'>,\n",
       " <ConnectionType.AZURE_BLOB_STORAGE: 'AzureBlob'>,\n",
       " <ConnectionType.AZURE_AI_SERVICES: 'AIServices'>,\n",
       " <ConnectionType.AZURE_AI_SEARCH: 'CognitiveSearch'>,\n",
       " <ConnectionType.API_KEY: 'ApiKey'>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects.models import ConnectionType\n",
    "\n",
    "[ct for ct in ConnectionType]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"ai-mutazaaieastus2054278078742_aoai\",\n",
      " \"id\": \"/subscriptions/e9b9c71e-d2ba-4086-a5ed-2923e15962d9/resourceGroups/rg-mutaza-5102_ai/providers/Microsoft.MachineLearningServices/workspaces/ai-inference-eastus2/connections/ai-mutazaaieastus2054278078742_aoai\",\n",
      " \"authentication_type\": \"ApiKey\",\n",
      " \"connection_type\": \"AzureOpenAI\",\n",
      " \"endpoint_url\": \"https://ai-mutazaaieastus2054278078742.openai.azure.com\",\n",
      " \"key\": null\n",
      " \"token_credential\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn = project_client.connections.get_default(connection_type=ConnectionType.AZURE_OPEN_AI)\n",
    "\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function azure.ai.projects.telemetry._trace_function.trace_function.<locals>.decorator(func: Callable) -> Callable>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup tracing to console\n",
    "# # Requires opentelemetry-sdk\n",
    "# span_exporter = ConsoleSpanExporter()\n",
    "# tracer_provider = TracerProvider()\n",
    "# tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter))\n",
    "# trace.set_tracer_provider(tracer_provider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_azure_monitor(connection_string=project_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with project_client.inference.get_chat_completions_client() as chat_client:\n",
    "\n",
    "    response = chat_client.complete(\n",
    "        model=model_name, messages=[UserMessage(content=\"How many feet are in a mile?\")]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client.telemetry.get_connection_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client.telemetry.enable(destination=project_client.telemetry.get_connection_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project_client.telemetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client.telemetry.enable(destination=\"azure-ai-projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with project_client.inference.get_chat_completions_client() as chat_client:\n",
    "\n",
    "    response = chat_client.complete(\n",
    "        model=model_name, messages=[UserMessage(content=\"How many feet are in a mile?\")]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
