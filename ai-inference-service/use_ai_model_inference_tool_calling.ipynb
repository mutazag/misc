{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "\n",
    "\n",
    "# [START trace_setting]\n",
    "from azure.core.settings import settings\n",
    "\n",
    "settings.tracing_implementation = \"opentelemetry\"\n",
    "# [END trace_setting]\n",
    "\n",
    "# [START instrument_inferencing]\n",
    "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
    "\n",
    "# Instrument AI Inference API\n",
    "AIInferenceInstrumentor().instrument()\n",
    "# [END instrument_inferencing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "1. gpt-4o\n",
      "2. DeepSeek-R1\n",
      "3. Phi-4-mini-instruct\n",
      "4. Phi-4-multimodal-instruct (version:1)\n",
      "5. o3-mini\n",
      "Selected model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"gpt-4o\": \"gpt-4o\",\n",
    "    \"DeepSeek-R1\": \"DeepSeek-R1\",\n",
    "    \"Phi-4-mini-instruct\": \"Phi-4-mini-instruct\",\n",
    "    \"Phi-4-multimodal-instruct (version:1)\": \"Phi-4-multimodal-instruct\",\n",
    "\n",
    "    \"o3-mini\": \"o3-mini\",\n",
    "}\n",
    "\n",
    "# Display available models\n",
    "print(\"Available models:\")\n",
    "for i, model_name in enumerate(models.keys()):\n",
    "    print(f\"{i+1}. {model_name}\")\n",
    "\n",
    "# Prompt user for selection\n",
    "selection = input(\"Select a model (enter number): \")\n",
    "try:\n",
    "    selection_idx = int(selection) - 1\n",
    "    model_keys = list(models.keys())\n",
    "    if 0 <= selection_idx < len(model_keys):\n",
    "        selected_model = models[model_keys[selection_idx]]\n",
    "        print(f\"Selected model: {selected_model}\")\n",
    "    else:\n",
    "        print(\"Invalid selection. Using default model 'gpt-4o'\")\n",
    "        selected_model = \"gpt-4o\"\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Using default model 'gpt-4o'\")\n",
    "    selected_model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider, AzureCliCredential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    ToolMessage,\n",
    "    AssistantMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilise a Chat Completion Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT\")\n",
    "# inferencekey = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT_KEY\")\n",
    "\n",
    "\n",
    "endpoint = os.getenv(\"GITHUB_INFERENCE_ENDPOINT\")\n",
    "inferencekey = os.getenv(\"GITHUB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(inferencekey),\n",
    "    credential_scopes=[\"https://cognitiveservices.azure.com/.default\"],\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a basic Chat Completion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    UserMessage(content=\"1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\n",
      "It would still take **1 hour** to dry 3 shirts, assuming they are being dried under the same conditions (e.g., they are dried in parallel, not one after the other). Drying multiple shirts simultaneously doesn't increase the drying time if all are exposed to the same drying conditions at the same time.\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)\n",
    "# gpt-4o\n",
    "response = client.complete(\n",
    "    messages = messages,\n",
    "    model = selected_model\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling\n",
    "\n",
    "![Tool calling flow](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/bS00MzkxMDI5LUM2YTczNA?revision=7&image-dimensions=2000x2000&constrain-image=true \"Tool calling flow\")\n",
    "\n",
    "\n",
    "Using tools requires the following parts \n",
    "- Tool definition using `ChatCompletionsToolDefinition` and `FunctionDefinition`\n",
    "- Tool function, e.g. `get_weather`\n",
    "- Tool message holding the result of a tool call, using `ToolMessage`\n",
    "\n",
    "The process to perform a tool call: \n",
    "1. Define the tool using `ChatCompletionsToolDefinition` and create a function \n",
    "\n",
    "2. Create a chat completion request and pass an array of defined tools \n",
    "   1. append response message to chat history (`messages`)\n",
    "\n",
    "3. Inspect the response from the chat completion for existence of tool calls, `response.choices[0].message.tool_calls`\n",
    "   1. In case a tool call existes in response, extract the tool call details (function name, arguments, tool call id) and call the function\n",
    "   2. Create a `ToolMessage` object with tool call id and function result as content\n",
    "   3. Append the `ToolMessage` to the chat history (`messages`)\n",
    "\n",
    "4. Send the updated chat history to the chat completion API again\n",
    "\n",
    "references:\n",
    "- https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/how-to/use-chat-completions?pivots=programming-language-python#use-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential lirbaries for Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    FunctionDefinition,\n",
    "    ChatCompletionsToolDefinition,\n",
    "\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    ToolMessage,\n",
    "\n",
    "    CompletionsFinishReason,\n",
    "\n",
    ")\n",
    "\n",
    "from azure.ai.inference import (\n",
    "    ChatCompletionsClient\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Functions\n",
    "\n",
    "This section shows the function definition and the function decleration itself.\n",
    "\n",
    "\n",
    "This schema represents the function signature and the parameters of the function. The function itself is defined in the next section.\n",
    "\n",
    "```python\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"Get the current time in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city name, e.g. San Francisco\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "Tools will be defined using SDK classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_def_get_weather = FunctionDefinition(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the weather for a given city\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city to get the weather for\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unit to use for the temperature (C or F)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "func_def_get_current_time = FunctionDefinition(\n",
    "    name=\"get_current_time\",\n",
    "    description=\"Get the current time in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city name, e.g. San Francisco\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "tools = [\n",
    "    ChatCompletionsToolDefinition(function=func_def_get_weather),\n",
    "    ChatCompletionsToolDefinition(function=func_def_get_current_time)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weather(city, unit=\"celsius\"):\n",
    "\n",
    "\n",
    "    \"\"\"Get the coordinates of a location using Nominatim.\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"my_user_agent\")\n",
    "    location = geolocator.geocode(city)\n",
    "\n",
    "    \"\"\"Get the weather for a given city\"\"\"\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={location.latitude}&longitude={location.longitude}&temperature_unit{unit}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "\n",
    "\n",
    "    print(f\"get_weather called with city: {city}, unit: {unit}\")\n",
    "\n",
    "    # Simulate getting weather data\n",
    "    weather_data = {\n",
    "        \"city\": city,\n",
    "        \"temperature\": data['current']['temperature_2m'],\n",
    "        \"unit\": unit,\n",
    "        \"description\": \"no description\"\n",
    "    }\n",
    "    return json.dumps(weather_data)\n",
    "\n",
    "def get_current_time(location):\n",
    "    from datetime import datetime\n",
    "    \"\"\"Get the current time for a given location\"\"\"\n",
    "    print(f\"get_current_time called with location: {location}\")\n",
    "    location_lower = location.lower()\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"current_time\": current_time\n",
    "    })\n",
    "\n",
    "    print(f\"No timezone data found for {location_lower}\")\n",
    "    return json.dumps({\"location\": location, \"current_time\": \"unknown\"})\n",
    "\n",
    "# print(get_weather(\"Sydney\", \"C\"))\n",
    "# print(get_current_time(\"Sydney\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first call \n",
    "\n",
    "In the first call we pass th user message in the message history, and the tool definition in the tools parameter.\n",
    "\n",
    "Must inspect the finish reason in the response. If the finish reason is `TOOL_CALLS` then we need to call the function and pass the result back to the chat completion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reason:  CompletionsFinishReason.TOOL_CALLS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'tool_calls': [{'function': {'arguments': '{\"location\": \"Melbourne\"}',\n",
       "    'name': 'get_current_time'},\n",
       "   'id': 'call_gBHqGnNGvDTSHA1GnbrWbFfq',\n",
       "   'type': 'function'},\n",
       "  {'function': {'arguments': '{\"city\": \"Melbourne\", \"unit\": \"C\"}',\n",
       "    'name': 'get_weather'},\n",
       "   'id': 'call_afakH4HwGmPbbYckGqRlnpbV',\n",
       "   'type': 'function'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    UserMessage(content=\"What is the time and temperature now in Melbourne\")\n",
    "]\n",
    "\n",
    "\n",
    "first_response = client.complete(\n",
    "    messages=message_history,\n",
    "    model = selected_model,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "#inspect first_response\n",
    "print(\"finish reason: \", first_response.choices[0].finish_reason)\n",
    "first_response.choices[0].message.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish reasons\n",
    "\n",
    "`CompletionsFinishReason` is an enum that defines the possible reasons for a completion to finish.\n",
    "\n",
    "\n",
    "The enum values are:\n",
    "```python\n",
    "CompletionsFinishReason.CONTENT_FILTERED\n",
    "CompletionsFinishReason.STOPPED\n",
    "CompletionsFinishReason.TOOL_CALLS\n",
    "CompletionsFinishReason.TOKEN_LIMIT_REACHED\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_reason = first_response.choices[0].finish_reason\n",
    "\n",
    "response_message = first_response.choices[0].message\n",
    "tool_calls = response_message.tool_calls if finish_reason == CompletionsFinishReason.TOOL_CALLS else []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append response_message to chat history and perform tool calls\n",
    "message_history.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the time and temperature now in Melbourne'},\n",
       " {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{\"location\": \"Melbourne\"}', 'name': 'get_current_time'}, 'id': 'call_gBHqGnNGvDTSHA1GnbrWbFfq', 'type': 'function'}, {'function': {'arguments': '{\"city\": \"Melbourne\", \"unit\": \"C\"}', 'name': 'get_weather'}, 'id': 'call_afakH4HwGmPbbYckGqRlnpbV', 'type': 'function'}]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing function calls using locals() and dictionary unpacking with ** \n",
    "\n",
    "\n",
    "All the function calls are equivalent to each other. \n",
    "\n",
    "\n",
    "```python\n",
    "function_name= \"get_weather\"\n",
    "function_args = {\n",
    "    \"city\": \"Sydney\",\n",
    "    \"unit\": \"C\"\n",
    "}\n",
    "\n",
    "locals()[function_name](**function_args)\n",
    "# equivalant to\n",
    "locals()['get_weather'](**{'city': 'Sydney', 'unit': 'C'})\\\n",
    "# and\n",
    "get_weather(city=\"Sydney\", unit=\"C\")\n",
    "# and\n",
    "get_weather(**{\"city\": \"Sydney\", \"unit\": \"C\"})\n",
    "```\n",
    "\n",
    "and will produce the same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_time called with location: Melbourne\n",
      "Tool Call ID: call_gBHqGnNGvDTSHA1GnbrWbFfq\n",
      "Function: get_current_time\n",
      "Arguments: {\n",
      "  \"location\": \"Melbourne\"\n",
      "}\n",
      "Results: {\"location\": \"Melbourne\", \"current_time\": \"06:31 PM\"}\n",
      "---\n",
      "get_weather called with city: Melbourne, unit: C\n",
      "Tool Call ID: call_afakH4HwGmPbbYckGqRlnpbV\n",
      "Function: get_weather\n",
      "Arguments: {\n",
      "  \"city\": \"Melbourne\",\n",
      "  \"unit\": \"C\"\n",
      "}\n",
      "Results: {\"city\": \"Melbourne\", \"temperature\": 17.2, \"unit\": \"C\", \"description\": \"no description\"}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    tool_call_id = tool_call.id\n",
    "\n",
    "\n",
    "\n",
    "    # execute the function call and append the results as a ToolMessage in the message history\n",
    "    function_call_results = locals()[function_name](**function_args)\n",
    "\n",
    "    message_history.append(\n",
    "        ToolMessage(\n",
    "            tool_call_id=tool_call_id,\n",
    "            content=function_call_results\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Tool Call ID: {tool_call_id}\")\n",
    "    print(f\"Function: {function_name}\")\n",
    "    print(f\"Arguments: {json.dumps(function_args, indent=2)}\")\n",
    "    print(f\"Results: {function_call_results}\")\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a helpful assistant.'}\n",
      "---\n",
      "{'role': 'user', 'content': 'What is the time and temperature now in Melbourne'}\n",
      "---\n",
      "{'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{\"location\": \"Melbourne\"}', 'name': 'get_current_time'}, 'id': 'call_gBHqGnNGvDTSHA1GnbrWbFfq', 'type': 'function'}, {'function': {'arguments': '{\"city\": \"Melbourne\", \"unit\": \"C\"}', 'name': 'get_weather'}, 'id': 'call_afakH4HwGmPbbYckGqRlnpbV', 'type': 'function'}]}\n",
      "---\n",
      "{'role': 'tool', 'tool_call_id': 'call_gBHqGnNGvDTSHA1GnbrWbFfq', 'content': '{\"location\": \"Melbourne\", \"current_time\": \"06:31 PM\"}'}\n",
      "---\n",
      "{'role': 'tool', 'tool_call_id': 'call_afakH4HwGmPbbYckGqRlnpbV', 'content': '{\"city\": \"Melbourne\", \"temperature\": 17.2, \"unit\": \"C\", \"description\": \"no description\"}'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "## inspect message history after adding tool call results\n",
    "for message in message_history:\n",
    "    print(message.as_dict())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send results of Tool Calls\n",
    "\n",
    "after the function call is executed, we need to send the result back to the chat completion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response:  Currently, in Melbourne, the time is 6:31 PM, and the temperature is 17.2°C.\n"
     ]
    }
   ],
   "source": [
    "if finish_reason == CompletionsFinishReason.TOOL_CALLS:\n",
    "    final_response = client.complete(\n",
    "        messages=message_history,\n",
    "        model = selected_model,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    print(\"Final Response: \", final_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START uninstrument_inferencing]\n",
    "AIInferenceInstrumentor().uninstrument()\n",
    "# [END uninstrument_inferencing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED'] = 'true'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
