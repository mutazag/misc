{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "1. gpt-4o\n",
      "2. DeepSeek-R1\n",
      "3. Phi-4-mini-instruct\n",
      "4. Phi-4-multimodal-instruct (version:1)\n",
      "5. o3-mini\n",
      "Selected model: DeepSeek-R1\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"gpt-4o\": \"gpt-4o\",\n",
    "    \"DeepSeek-R1\": \"DeepSeek-R1\",\n",
    "    \"Phi-4-mini-instruct\": \"Phi-4-mini-instruct\",\n",
    "    \"Phi-4-multimodal-instruct (version:1)\": \"Phi-4-multimodal-instruct\",\n",
    "\n",
    "    \"o3-mini\": \"o3-mini\",\n",
    "}\n",
    "\n",
    "# Display available models\n",
    "print(\"Available models:\")\n",
    "for i, model_name in enumerate(models.keys()):\n",
    "    print(f\"{i+1}. {model_name}\")\n",
    "\n",
    "# Prompt user for selection\n",
    "selection = input(\"Select a model (enter number): \")\n",
    "try:\n",
    "    selection_idx = int(selection) - 1\n",
    "    model_keys = list(models.keys())\n",
    "    if 0 <= selection_idx < len(model_keys):\n",
    "        selected_model = models[model_keys[selection_idx]]\n",
    "        print(f\"Selected model: {selected_model}\")\n",
    "    else:\n",
    "        print(\"Invalid selection. Using default model 'gpt-4o'\")\n",
    "        selected_model = \"gpt-4o\"\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Using default model 'gpt-4o'\")\n",
    "    selected_model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider, AzureCliCredential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    ToolMessage,\n",
    "    AssistantMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilise a Chat Completion Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT_KEY\")),\n",
    "    credential_scopes=[\"https://cognitiveservices.azure.com/.default\"],\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a basic Chat Completion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    UserMessage(content=\"1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 shirt needs 1 hour to dry, how long does it take to dry 3 shirts?\n",
      "<think>\n",
      "Okay, so the question is: \"If 1 shirt takes 1 hour to dry, how long does it take to dry 3 shirts?\" At first glance, it seems straightforward, but let me think about it carefully.\n",
      "\n",
      "Hmm, when they say 1 shirt needs 1 hour to dry, is that assuming that you're drying just one shirt by itself? Like, if you hang one shirt outside, it dries in an hour. Now, if you have three shirts, do you need more time, or is it still the same? Wait, maybe it depends on how you're drying them. If you have enough space and the drying conditions are the same for each shirt, then maybe all three can dry simultaneously without affecting each other's drying time. So, if you put three shirts on a clothesline, each exposed to the same amount of air and sunlight, each would take 1 hour to dry, right? So, regardless of the number, as long as they're dried at the same time, it's still 1 hour.\n",
      "\n",
      "But maybe the question is trying to trick me. Sometimes in these problems, people might think that more shirts would take longer, like if you have more clothes in a dryer, it takes more time. But in this case, it's not specified whether it's a dryer or air-drying. If it's a dryer, maybe adding more shirts would increase drying time because the dryer has to work harder, but the problem doesn't mention a dryer. It just says \"dry.\" So, maybe it's air-drying. In that case, as long as they're spread out and have enough space, they should all dry in the same time as one shirt.\n",
      "\n",
      "Wait, but what if the drying area is limited? Like, if you have a small space and you put three shirts close together, maybe they block each other's airflow, so they take longer to dry. But the problem doesn't mention any space constraints. Hmm. In the absence of specific information, maybe we have to assume ideal conditions where each shirt can dry independently. So, the answer would be 1 hour.\n",
      "\n",
      "But let me check. If I have three shirts hanging on a line, each with enough space between them, under the sun with a breeze, they all should dry in the same time as one. But maybe if they are overlapping or in a confined space, but the question doesn't specify that. So, by default, it's 1 hour. So, maybe the trick is to realize that drying time isn't affected by the number of shirts if they are dried simultaneously under the same conditions.\n",
      "\n",
      "Alternatively, if you have to dry them sequentially, like only one shirt can be dried at a time, then three shirts would take 3 hours. But that seems like a different scenario. The problem says \"how long does it take to dry 3 shirts?\" without specifying any constraints on drying method. So, maybe it's a trick question where the answer is still 1 hour because you can dry them all at once.\n",
      "\n",
      "So, considering different perspectives: If you can dry all shirts at the same time, 1 hour. If you have to dry them one after another, 3 hours. But since the problem doesn't specify any limitation on drying multiple shirts at once, the answer is 1 hour. But maybe the question is from a non-English context where they expect cumulative time? Hmm. Let me see.\n",
      "\n",
      "Wait, in some logic puzzles, similar questions are asked where if one candle burns for 1 hour, how long do three burn? The answer is still 1 hour because they burn simultaneously. So, same logic applies here. Unless drying time per shirt increases with more shirts, but without evidence of that, it's safe to assume they dry in parallel. Therefore, 1 hour.\n",
      "</think>\n",
      "\n",
      "The drying time for shirts is independent of the number of shirts if they are dried simultaneously under the same conditions. Since the problem does not specify any constraints (e.g., limited drying space), we assume ideal conditions where all three shirts can dry at the same time. \n",
      "\n",
      "**Answer:** 1 hour.\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)\n",
    "# gpt-4o\n",
    "response = client.complete(\n",
    "    messages = messages,\n",
    "    model = selected_model\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling\n",
    "\n",
    "![Tool calling flow](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/bS00MzkxMDI5LUM2YTczNA?revision=7&image-dimensions=2000x2000&constrain-image=true \"Tool calling flow\")\n",
    "\n",
    "\n",
    "Using tools requires the following parts \n",
    "- Tool definition using `ChatCompletionsToolDefinition` and `FunctionDefinition`\n",
    "- Tool function, e.g. `get_weather`\n",
    "- Tool message holding the result of a tool call, using `ToolMessage`\n",
    "\n",
    "The process to perform a tool call: \n",
    "1. Define the tool using `ChatCompletionsToolDefinition` and create a function \n",
    "\n",
    "2. Create a chat completion request and pass an array of defined tools \n",
    "   1. append response message to chat history (`messages`)\n",
    "\n",
    "3. Inspect the response from the chat completion for existence of tool calls, `response.choices[0].message.tool_calls`\n",
    "   1. In case a tool call existes in response, extract the tool call details (function name, arguments, tool call id) and call the function\n",
    "   2. Create a `ToolMessage` object with tool call id and function result as content\n",
    "   3. Append the `ToolMessage` to the chat history (`messages`)\n",
    "\n",
    "4. Send the updated chat history to the chat completion API again\n",
    "\n",
    "references:\n",
    "- https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/how-to/use-chat-completions?pivots=programming-language-python#use-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential lirbaries for Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    FunctionDefinition,\n",
    "    ChatCompletionsToolDefinition,\n",
    "\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    ToolMessage,\n",
    "\n",
    "    CompletionsFinishReason,\n",
    "\n",
    ")\n",
    "\n",
    "from azure.ai.inference import (\n",
    "    ChatCompletionsClient\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Functions\n",
    "\n",
    "This section shows the function definition and the function decleration itself.\n",
    "\n",
    "\n",
    "This schema represents the function signature and the parameters of the function. The function itself is defined in the next section.\n",
    "\n",
    "```python\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"Get the current time in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city name, e.g. San Francisco\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "Tools will be defined using SDK classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_def_get_weather = FunctionDefinition(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the weather for a given city\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city to get the weather for\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unit to use for the temperature (C or F)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "func_def_get_current_time = FunctionDefinition(\n",
    "    name=\"get_current_time\",\n",
    "    description=\"Get the current time in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city name, e.g. San Francisco\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "tools = [\n",
    "    ChatCompletionsToolDefinition(function=func_def_get_weather),\n",
    "    ChatCompletionsToolDefinition(function=func_def_get_current_time)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather called with city: Sydney, unit: C\n",
      "{\"city\": \"Sydney\", \"temperature\": \"20\", \"unit\": \"C\", \"description\": \"Sunny\"}\n",
      "get_current_time called with location: Sydney\n",
      "{\"location\": \"Sydney\", \"current_time\": \"05:22 PM\"}\n"
     ]
    }
   ],
   "source": [
    "def get_weather(city, unit=\"C\"):\n",
    "    \"\"\"Get the weather for a given city\"\"\"\n",
    "    print(f\"get_weather called with city: {city}, unit: {unit}\")\n",
    "    # Simulate getting weather data\n",
    "    weather_data = {\n",
    "        \"city\": city,\n",
    "        \"temperature\": \"20\",\n",
    "        \"unit\": unit,\n",
    "        \"description\": \"Sunny\"\n",
    "    }\n",
    "    return json.dumps(weather_data)\n",
    "\n",
    "def get_current_time(location):\n",
    "    from datetime import datetime\n",
    "    \"\"\"Get the current time for a given location\"\"\"\n",
    "    print(f\"get_current_time called with location: {location}\")\n",
    "    location_lower = location.lower()\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"current_time\": current_time\n",
    "    })\n",
    "\n",
    "    print(f\"No timezone data found for {location_lower}\")\n",
    "    return json.dumps({\"location\": location, \"current_time\": \"unknown\"})\n",
    "\n",
    "print(get_weather(\"Sydney\", \"C\"))\n",
    "print(get_current_time(\"Sydney\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first call \n",
    "\n",
    "In the first call we pass th user message in the message history, and the tool definition in the tools parameter.\n",
    "\n",
    "Must inspect the finish reason in the response. If the finish reason is `TOOL_CALLS` then we need to call the function and pass the result back to the chat completion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reason:  CompletionsFinishReason.STOPPED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': \"<think>\\nOkay, the user is asking for the current time and weather in Sydney. Since I can't access real-time data, I need to let them know that. But I should still be helpful. Maybe suggest checking a reliable website or app for that info. Also, mention that Sydney is in Australia, just in case there's any confusion with other Sydneys. Keep the response friendly and offer further help if needed.\\n\\nAlright, structure the response: Start by stating I can't provide real-time data. Then suggest using a weather website or app. Mention the time zone part. Offer to help convert time zones if they need. Keep it concise and polite.\\n</think>\\n\\nI can't provide real-time data like current weather or time, but you can quickly check these details for Sydney, Australia, using services like **Google Search**, **Weather.com**, or a weather app. Sydney typically follows Australian Eastern Daylight Time (AEDT) UTC+11 during daylight saving (Oct-Apr) and Australian Eastern Standard Time (AEST) UTC+10 otherwise. Let me know if you'd like help converting time zones! üå§Ô∏è\",\n",
       " 'reasoning_content': None,\n",
       " 'role': 'assistant',\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    UserMessage(content=\"What is the time and weather in Sydney?\")\n",
    "]\n",
    "\n",
    "\n",
    "first_response = client.complete(\n",
    "    messages=message_history,\n",
    "    model = selected_model,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "#inspect first_response\n",
    "print(\"finish reason: \", first_response.choices[0].finish_reason)\n",
    "first_response.choices[0].message.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish reasons\n",
    "\n",
    "`CompletionsFinishReason` is an enum that defines the possible reasons for a completion to finish.\n",
    "\n",
    "\n",
    "The enum values are:\n",
    "```python\n",
    "CompletionsFinishReason.CONTENT_FILTERED\n",
    "CompletionsFinishReason.STOPPED\n",
    "CompletionsFinishReason.TOOL_CALLS\n",
    "CompletionsFinishReason.TOKEN_LIMIT_REACHED\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_reason = first_response.choices[0].finish_reason\n",
    "\n",
    "response_message = first_response.choices[0].message\n",
    "tool_calls = response_message.tool_calls if finish_reason == CompletionsFinishReason.TOOL_CALLS else []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append response_message to chat history and perform tool calls\n",
    "message_history.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the time and weather in Sydney?'},\n",
       " {'content': \"<think>\\nOkay, the user is asking for the current time and weather in Sydney. Since I can't access real-time data, I need to let them know that. But I should still be helpful. Maybe suggest checking a reliable website or app for that info. Also, mention that Sydney is in Australia, just in case there's any confusion with other Sydneys. Keep the response friendly and offer further help if needed.\\n\\nAlright, structure the response: Start by stating I can't provide real-time data. Then suggest using a weather website or app. Mention the time zone part. Offer to help convert time zones if they need. Keep it concise and polite.\\n</think>\\n\\nI can't provide real-time data like current weather or time, but you can quickly check these details for Sydney, Australia, using services like **Google Search**, **Weather.com**, or a weather app. Sydney typically follows Australian Eastern Daylight Time (AEDT) UTC+11 during daylight saving (Oct-Apr) and Australian Eastern Standard Time (AEST) UTC+10 otherwise. Let me know if you'd like help converting time zones! üå§Ô∏è\", 'reasoning_content': None, 'role': 'assistant', 'tool_calls': None}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing function calls using locals() and dictionary unpacking with ** \n",
    "\n",
    "\n",
    "All the function calls are equivalent to each other. \n",
    "\n",
    "\n",
    "```python\n",
    "function_name= \"get_weather\"\n",
    "function_args = {\n",
    "    \"city\": \"Sydney\",\n",
    "    \"unit\": \"C\"\n",
    "}\n",
    "\n",
    "locals()[function_name](**function_args)\n",
    "# equivalant to\n",
    "locals()['get_weather'](**{'city': 'Sydney', 'unit': 'C'})\\\n",
    "# and\n",
    "get_weather(city=\"Sydney\", unit=\"C\")\n",
    "# and\n",
    "get_weather(**{\"city\": \"Sydney\", \"unit\": \"C\"})\n",
    "```\n",
    "\n",
    "and will produce the same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    tool_call_id = tool_call.id\n",
    "\n",
    "\n",
    "\n",
    "    # execute the function call and append the results as a ToolMessage in the message history\n",
    "    function_call_results = locals()[function_name](**function_args)\n",
    "\n",
    "    message_history.append(\n",
    "        ToolMessage(\n",
    "            tool_call_id=tool_call_id,\n",
    "            content=function_call_results\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Tool Call ID: {tool_call_id}\")\n",
    "    print(f\"Function: {function_name}\")\n",
    "    print(f\"Arguments: {json.dumps(function_args, indent=2)}\")\n",
    "    print(f\"Results: {function_call_results}\")\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a helpful assistant.'}\n",
      "---\n",
      "{'role': 'user', 'content': 'What is the time and weather in Sydney?'}\n",
      "---\n",
      "{'content': \"<think>\\nOkay, the user is asking for the current time and weather in Sydney. Since I can't access real-time data, I need to let them know that. But I should still be helpful. Maybe suggest checking a reliable website or app for that info. Also, mention that Sydney is in Australia, just in case there's any confusion with other Sydneys. Keep the response friendly and offer further help if needed.\\n\\nAlright, structure the response: Start by stating I can't provide real-time data. Then suggest using a weather website or app. Mention the time zone part. Offer to help convert time zones if they need. Keep it concise and polite.\\n</think>\\n\\nI can't provide real-time data like current weather or time, but you can quickly check these details for Sydney, Australia, using services like **Google Search**, **Weather.com**, or a weather app. Sydney typically follows Australian Eastern Daylight Time (AEDT) UTC+11 during daylight saving (Oct-Apr) and Australian Eastern Standard Time (AEST) UTC+10 otherwise. Let me know if you'd like help converting time zones! üå§Ô∏è\", 'reasoning_content': None, 'role': 'assistant', 'tool_calls': None}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "## inspect message history after adding tool call results\n",
    "for message in message_history:\n",
    "    print(message.as_dict())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send results of Tool Calls\n",
    "\n",
    "after the function call is executed, we need to send the result back to the chat completion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if finish_reason == CompletionsFinishReason.TOOL_CALLS:\n",
    "    final_response = client.complete(\n",
    "        messages=message_history,\n",
    "        model = selected_model,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    print(\"Final Response: \", final_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
