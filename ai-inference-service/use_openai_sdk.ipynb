{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d4552b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a43e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://magoai-eastus2.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"o3-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db532318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  # e.g. \"https://your-resource-name.openai.azure.com\"\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  # The API key for your Azure OpenAI resource\n",
    "    api_version=\"2023-05-15\"  # The API version to use\n",
    ")\n",
    "\n",
    "# Alternatively, you can also specify the deployment directly during client creation\n",
    "# deployment=\"o3-mini\"  # This is the deployment name you set in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a707fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message(role, content):\n",
    "    return {\"role\": role, \"content\":\n",
    "            [{\"type\": \"text\",\n",
    "             \"text\": content}]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version=\"2024-12-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9458314",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8998db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e466a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"developer\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"type\": \"text\",\n",
      "        \"text\": \"You are an AI assistant that helps people find information.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"type\": \"text\",\n",
      "        \"text\": \"It takes 2 hours to dry one shirt, how many hours does it take to dry 8 shirts?\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "messages = chat_prompt\n",
    "messages.append(message(role=\"user\", content=\"It takes 2 hours to dry one shirt, how many hours does it take to dry 8 shirts?\"))\n",
    "\n",
    "print(json.dumps(messages, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7bff3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-B9kUxj0bAtTUrKNun4J0fNQNuhZ3o\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"It still takes 2 hours. Drying is a process that happens concurrently rather than sequentially – if you can hang all 8 shirts to dry at the same time under the same conditions, then they will all finish drying in 2 hours.\\n\\nHowever, if you were forced to dry the shirts one after the other (which is usually not the case), then it would take 16 hours. But typically, when drying clothes, you’re drying them all at once.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1741663391,\n",
      "  \"model\": \"o3-mini-2025-01-31\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_ded0d14823\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 882,\n",
      "    \"prompt_tokens\": 43,\n",
      "    \"total_tokens\": 925,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 768,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=messages,\n",
    "    max_completion_tokens=100000,\n",
    "    stop=None,\n",
    "    stream=False ,\n",
    "\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "print(completion.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6dd1577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: It still takes 2 hours. Drying is a process that happens concurrently rather than sequentially – if you can hang all 8 shirts to dry at the same time under the same conditions, then they will all finish drying in 2 hours.\n",
      "\n",
      "However, if you were forced to dry the shirts one after the other (which is usually not the case), then it would take 16 hours. But typically, when drying clothes, you’re drying them all at once.\n",
      "reasoning effort: 768\n"
     ]
    }
   ],
   "source": [
    "print( f\"response: {completion.choices[0].message.content}\")\n",
    "print( f\"reasoning effort: {completion.usage.completion_tokens_details.reasoning_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6263e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
