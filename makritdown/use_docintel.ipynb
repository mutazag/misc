{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import (\n",
    "    AnalyzeResult,\n",
    "    DocumentAnalysisFeature,\n",
    "    AnalyzeOutputOption,\n",
    "    DocumentContentFormat,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, AzureCliCredential\n",
    "from markitdown import MarkItDown\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689b30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _in_span(word, spans):\n",
    "    for span in spans:\n",
    "        if word.span.offset >= span.offset and (word.span.offset + word.span.length) <= (span.offset + span.length):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _format_polygon(polygon):\n",
    "    if not polygon:\n",
    "        return \"N/A\"\n",
    "    return \", \".join([f\"[{polygon[i]}, {polygon[i + 1]}]\" for i in range(0, len(polygon), 2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7206dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_intelligence_client = di = DocumentIntelligenceClient(\n",
    "    endpoint=os.getenv(\"DOC_INTELLIGENCE_API\"),\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc67b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_intelligence_client._config.api_version = \"2024-11-30\"  # Set the API version to the latest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4bf7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Intelligence SDK version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.documentintelligence import VERSION as doc_intelligence_version\n",
    "print(f\"Document Intelligence SDK version: {doc_intelligence_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d3b92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-30'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_intelligence_client._config.api_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1607db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_sample_documents = \"data/Northwind_Standard_Benefits_Details.pdf\"\n",
    "path_to_sample_documents = \"data/Small business startup checklis1.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1031434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_to_sample_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mpath_to_sample_documents\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     poller = document_intelligence_client.begin_analyze_document(\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprebuilt-read\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m         body=f,\n\u001b[32m      5\u001b[39m         \u001b[38;5;66;03m# pages=\"3\",\u001b[39;00m\n\u001b[32m      6\u001b[39m         \u001b[38;5;66;03m# output_content_format=DocumentContentFormat.MARKDOWN,\u001b[39;00m\n\u001b[32m      7\u001b[39m     )\n\u001b[32m      8\u001b[39m result: AnalyzeResult = poller.result()\n",
      "\u001b[31mNameError\u001b[39m: name 'path_to_sample_documents' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(path_to_sample_documents, \"rb\") as f:\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-read\",\n",
    "        body=f,\n",
    "        # pages=\"3\",\n",
    "        # output_content_format=DocumentContentFormat.MARKDOWN,\n",
    "    )\n",
    "result: AnalyzeResult = poller.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb801385",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d11859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sample_documents = \"data/Northwind_Standard_Benefits_Details.pdf\"\n",
    "with open(path_to_sample_documents, \"rb\") as f:\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\",\n",
    "        body=f,\n",
    "        pages=\"4-8\",\n",
    "        output_content_format=DocumentContentFormat.MARKDOWN,\n",
    "    )\n",
    "result: AnalyzeResult = poller.result()\n",
    "print(f\"Document has {len(result.pages)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e59f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(type(result))\n",
    "# print(json.dumps(result.as_dict(), indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.as_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get(\"pages\")\n",
    "\n",
    "\n",
    "\n",
    "display(pd.json_normalize(result.as_dict()['pages'], sep=\"_\").head(5))\n",
    "display(pd.json_normalize(result.as_dict()['paragraphs'], sep=\"_\").head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e83f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Pydantic models for Document Intelligence results\n",
    "class Span(pydantic.BaseModel):\n",
    "    offset: int\n",
    "    length: int\n",
    "\n",
    "class DocumentWord(pydantic.BaseModel):\n",
    "    content: str\n",
    "    polygon: list[float] = None\n",
    "    confidence: float\n",
    "    span: Span\n",
    "\n",
    "class BoundingRegion(pydantic.BaseModel):\n",
    "    page_number: int\n",
    "    polygon: list[float] = None\n",
    "\n",
    "class Paragraph(pydantic.BaseModel):\n",
    "    content: str\n",
    "    role: str = None\n",
    "    spans: list[Span]\n",
    "    bounding_regions: list[BoundingRegion] = None\n",
    "\n",
    "# Parse words and paragraphs\n",
    "words = [DocumentWord(**word) for word in result.as_dict()['words']] if 'words' in result.as_dict() else []\n",
    "paragraphs = [Paragraph(**para) for para in result.as_dict()['paragraphs']] if 'paragraphs' in result.as_dict() else []\n",
    "\n",
    "# Display some examples\n",
    "print(f\"Total words: {len(words)}\")\n",
    "if words:\n",
    "    print(f\"Sample word: {words[0].content}, confidence: {words[0].confidence}\")\n",
    "\n",
    "print(f\"Total paragraphs: {len(paragraphs)}\")\n",
    "if paragraphs:\n",
    "    print(f\"Sample paragraph: {paragraphs[0].content[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content_format)\n",
    "\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if result.styles and any([style.is_handwritten for style in result.styles]):\n",
    "    print(\"Document contains handwritten content\")\n",
    "else:\n",
    "    print(\"Document does not contain handwritten content\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Document has {len(result.pages)} pages\")\n",
    "for page in result.pages:\n",
    "    print(f\"----Analyzing layout from page #{page.page_number}----\")\n",
    "    print(f\"Page has width: {page.width} and height: {page.height}, measured with unit: {page.unit}\")\n",
    "\n",
    "    # if page.lines:\n",
    "    #     for line_idx, line in enumerate(page.lines):\n",
    "    #         words = []\n",
    "    #         if page.words:\n",
    "    #             for word in page.words:\n",
    "    #                 print(f\"......Word '{word.content}' has a confidence of {word.confidence}\")\n",
    "    #                 if _in_span(word, line.spans):\n",
    "    #                     words.append(word)\n",
    "    #         print(\n",
    "    #             f\"...Line # {line_idx} has word count {len(words)} and text '{line.content}' \"\n",
    "    #             f\"within bounding polygon '{_format_polygon(line.polygon)}'\"\n",
    "    #         )\n",
    "\n",
    "    # if page.selection_marks:\n",
    "    #     for selection_mark in page.selection_marks:\n",
    "    #         print(\n",
    "    #             f\"Selection mark is '{selection_mark.state}' within bounding polygon \"\n",
    "    #             f\"'{_format_polygon(selection_mark.polygon)}' and has a confidence of {selection_mark.confidence}\"\n",
    "    #         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if result.paragraphs:\n",
    "    print(f\"----Detected #{len(result.paragraphs)} paragraphs in the document----\")\n",
    "    # Sort all paragraphs by span's offset to read in the right order.\n",
    "    result.paragraphs.sort(key=lambda p: (p.spans.sort(key=lambda s: s.offset), p.spans[0].offset))\n",
    "    # print(\"-----Print sorted paragraphs-----\")\n",
    "    # for paragraph in result.paragraphs:\n",
    "    #     if not paragraph.bounding_regions:\n",
    "    #         print(f\"Found paragraph with role: '{paragraph.role}' within N/A bounding region\")\n",
    "    #     else:\n",
    "    #         print(f\"Found paragraph with role: '{paragraph.role}' within\")\n",
    "    #         print(\n",
    "    #             \", \".join(\n",
    "    #                 f\" Page #{region.page_number}: {_format_polygon(region.polygon)} bounding region\"\n",
    "    #                 for region in paragraph.bounding_regions\n",
    "    #             )\n",
    "    #         )\n",
    "    #     print(f\"...with content: '{paragraph.content}'\")\n",
    "    #     print(f\"...with offset: {paragraph.spans[0].offset} and length: {paragraph.spans[0].length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if result.tables:\n",
    "    for table_idx, table in enumerate(result.tables):\n",
    "        print(f\"Table # {table_idx} has {table.row_count} rows and \" f\"{table.column_count} columns\")\n",
    "        if table.bounding_regions:\n",
    "            for region in table.bounding_regions:\n",
    "                print(\n",
    "                    f\"Table # {table_idx} location on page: {region.page_number} is {_format_polygon(region.polygon)}\"\n",
    "                )\n",
    "        for cell in table.cells:\n",
    "            print(f\"...Cell[{cell.row_index}][{cell.column_index}] has text '{cell.content}'\")\n",
    "            if cell.bounding_regions:\n",
    "                for region in cell.bounding_regions:\n",
    "                    print(\n",
    "                        f\"...content on page {region.page_number} is within bounding polygon '{_format_polygon(region.polygon)}'\"\n",
    "                    )\n",
    "\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50489d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
