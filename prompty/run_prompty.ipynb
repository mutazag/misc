{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb43350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import prompty\n",
    "import prompty.azure\n",
    "import prompty.openai\n",
    "import prompty.serverless\n",
    "\n",
    "from prompty.tracer import (\n",
    "    trace,\n",
    "    Tracer,\n",
    "    console_tracer,\n",
    "    PromptyTracer\n",
    ")\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac32e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AZURE_OPENAI_ENDPOINT\n",
    "# AZURE_OPENAI_API_KEY\n",
    "# AZURE_OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86656922",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracer.add(\"console\", console_tracer)\n",
    "json_tracer = PromptyTracer()\n",
    "Tracer.add(\"PromptyTracer\", json_tracer.tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9a025b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "        question: any = \"What is the capital of France?\",\n",
    "\n",
    ") -> str:\n",
    "    result = prompty.execute(\n",
    "        os.getcwd() + \"/promptyfiles/aoai_basic_o3mini.prompty\",\n",
    "        inputs={\n",
    "            \"firstname\": \"John\",\n",
    "            \"context\": \"You are a helpful assistant.\",\n",
    "            \"question\": question,\n",
    "        }\n",
    "    )\n",
    "    return(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "072ba0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execute\n",
      "signature:\n",
      "\"prompty.execute\"\n",
      "description:\n",
      "\"Execute a prompty\"\n",
      "inputs:\n",
      "{\n",
      "    \"prompt\": \"c:\\\\git\\\\misc\\\\prompty/promptyfiles/aoai_basic_o3mini.prompty\",\n",
      "    \"configuration\": {},\n",
      "    \"parameters\": {},\n",
      "    \"inputs\": {\n",
      "        \"firstname\": \"John\",\n",
      "        \"context\": \"You are a helpful assistant.\",\n",
      "        \"question\": \"What is the capital of France?\"\n",
      "    },\n",
      "    \"raw\": false,\n",
      "    \"config_name\": \"default\"\n",
      "}\n",
      "Starting load\n",
      "signature:\n",
      "\"prompty.load\"\n",
      "description:\n",
      "\"Load a prompty file.\"\n",
      "inputs:\n",
      "{\n",
      "    \"prompty_file\": \"c:\\\\git\\\\misc\\\\prompty\\\\promptyfiles\\\\aoai_basic_o3mini.prompty\",\n",
      "    \"configuration\": \"default\"\n",
      "}\n",
      "result:\n",
      "{\n",
      "    \"name\": \"ExamplePrompt\",\n",
      "    \"description\": \"A prompt that uses context to ground an incoming question\",\n",
      "    \"authors\": [\n",
      "        \"Mutaz\"\n",
      "    ],\n",
      "    \"tags\": [],\n",
      "    \"version\": \"\",\n",
      "    \"base\": \"\",\n",
      "    \"basePrompty\": \"None\",\n",
      "    \"model\": {\n",
      "        \"api\": \"chat\",\n",
      "        \"configuration\": {\n",
      "            \"type\": \"azure_openai\",\n",
      "            \"azure_deployment\": \"o3-mini\",\n",
      "            \"api_key\": \"**********\",\n",
      "            \"api_version\": \"2024-05-01-preview\",\n",
      "            \"azure_endpoint\": \"2024-12-01-preview\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"max_tokens\": 3000,\n",
      "            \"temperature\": 0.5\n",
      "        },\n",
      "        \"response\": {}\n",
      "    },\n",
      "    \"sample\": {\n",
      "        \"firstName\": \"Ali\",\n",
      "        \"additional_context\": \"the  customer who is looking for information about new advanced AI models\",\n",
      "        \"question\": \"What can you tell me about latest AI models?\",\n",
      "        \"chat_history\": [\n",
      "            {\n",
      "                \"role\": \"user\",\n",
      "                \"content\": \"what's the capital of France?\"\n",
      "            },\n",
      "            {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Paris\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"inputs\": {\n",
      "        \"firstName\": {\n",
      "            \"type\": \"string\",\n",
      "            \"default\": \"None\",\n",
      "            \"description\": \"\"\n",
      "        },\n",
      "        \"additional_context\": {\n",
      "            \"type\": \"string\",\n",
      "            \"default\": \"None\",\n",
      "            \"description\": \"\"\n",
      "        },\n",
      "        \"question\": {\n",
      "            \"type\": \"string\",\n",
      "            \"default\": \"None\",\n",
      "            \"description\": \"\"\n",
      "        },\n",
      "        \"chat_history\": {\n",
      "            \"type\": \"list\",\n",
      "            \"default\": \"None\",\n",
      "            \"description\": \"\"\n",
      "        }\n",
      "    },\n",
      "    \"outputs\": {},\n",
      "    \"template\": {\n",
      "        \"type\": \"jinja2\",\n",
      "        \"parser\": \"prompty\"\n",
      "    },\n",
      "    \"file\": \"c:\\\\git\\\\misc\\\\prompty\\\\promptyfiles\\\\aoai_basic_o3mini.prompty\",\n",
      "    \"content\": \"system:\\nYou are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping {{firstName}} to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to {{firstName}}:\\n{{additional_context}}\\n\\nuser:\\n{{question}}\\n\"\n",
      "}\n",
      "Ending load\n",
      "Starting prepare\n",
      "signature:\n",
      "\"prompty.prepare\"\n",
      "description:\n",
      "\"Prepare the inputs for the prompt.\"\n",
      "inputs:\n",
      "{\n",
      "    \"prompt\": {\n",
      "        \"name\": \"ExamplePrompt\",\n",
      "        \"description\": \"A prompt that uses context to ground an incoming question\",\n",
      "        \"authors\": [\n",
      "            \"Mutaz\"\n",
      "        ],\n",
      "        \"tags\": [],\n",
      "        \"version\": \"\",\n",
      "        \"base\": \"\",\n",
      "        \"basePrompty\": \"None\",\n",
      "        \"model\": {\n",
      "            \"api\": \"chat\",\n",
      "            \"configuration\": {\n",
      "                \"type\": \"azure_openai\",\n",
      "                \"azure_deployment\": \"o3-mini\",\n",
      "                \"api_key\": \"**********\",\n",
      "                \"api_version\": \"2024-05-01-preview\",\n",
      "                \"azure_endpoint\": \"2024-12-01-preview\"\n",
      "            },\n",
      "            \"parameters\": {\n",
      "                \"max_tokens\": 3000,\n",
      "                \"temperature\": 0.5\n",
      "            },\n",
      "            \"response\": {}\n",
      "        },\n",
      "        \"sample\": {\n",
      "            \"firstName\": \"Ali\",\n",
      "            \"additional_context\": \"the  customer who is looking for information about new advanced AI models\",\n",
      "            \"question\": \"What can you tell me about latest AI models?\",\n",
      "            \"chat_history\": [\n",
      "                {\n",
      "                    \"role\": \"user\",\n",
      "                    \"content\": \"what's the capital of France?\"\n",
      "                },\n",
      "                {\n",
      "                    \"role\": \"assistant\",\n",
      "                    \"content\": \"Paris\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"inputs\": {\n",
      "            \"firstName\": {\n",
      "                \"type\": \"string\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            },\n",
      "            \"additional_context\": {\n",
      "                \"type\": \"string\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            },\n",
      "            \"question\": {\n",
      "                \"type\": \"string\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            },\n",
      "            \"chat_history\": {\n",
      "                \"type\": \"list\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {},\n",
      "        \"template\": {\n",
      "            \"type\": \"jinja2\",\n",
      "            \"parser\": \"prompty\"\n",
      "        },\n",
      "        \"file\": \"c:\\\\git\\\\misc\\\\prompty\\\\promptyfiles\\\\aoai_basic_o3mini.prompty\",\n",
      "        \"content\": \"system:\\nYou are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping {{firstName}} to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to {{firstName}}:\\n{{additional_context}}\\n\\nuser:\\n{{question}}\\n\"\n",
      "    },\n",
      "    \"inputs\": {\n",
      "        \"firstname\": \"John\",\n",
      "        \"context\": \"You are a helpful assistant.\",\n",
      "        \"question\": \"What is the capital of France?\"\n",
      "    }\n",
      "}\n",
      "Starting Jinja2Renderer\n",
      "signature:\n",
      "\"prompty.renderers.Jinja2Renderer.invoke\"\n",
      "inputs:\n",
      "{\n",
      "    \"data\": {\n",
      "        \"firstname\": \"John\",\n",
      "        \"context\": \"You are a helpful assistant.\",\n",
      "        \"question\": \"What is the capital of France?\",\n",
      "        \"firstName\": \"Ali\",\n",
      "        \"additional_context\": \"the  customer who is looking for information about new advanced AI models\",\n",
      "        \"chat_history\": [\n",
      "            {\n",
      "                \"role\": \"user\",\n",
      "                \"content\": \"what's the capital of France?\"\n",
      "            },\n",
      "            {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Paris\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "result:\n",
      "\"system:\\nYou are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\\n\\nuser:\\nWhat is the capital of France?\"\n",
      "Ending Jinja2Renderer\n",
      "Starting PromptyChatParser\n",
      "signature:\n",
      "\"prompty.parsers.PromptyChatParser.invoke\"\n",
      "inputs:\n",
      "{\n",
      "    \"data\": \"system:\\nYou are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\\n\\nuser:\\nWhat is the capital of France?\"\n",
      "}\n",
      "result:\n",
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What is the capital of France?\"\n",
      "    }\n",
      "]\n",
      "Ending PromptyChatParser\n",
      "result:\n",
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What is the capital of France?\"\n",
      "    }\n",
      "]\n",
      "Ending prepare\n",
      "Starting run\n",
      "signature:\n",
      "\"prompty.run\"\n",
      "description:\n",
      "\"Run the prepared Prompty content against the model.\"\n",
      "inputs:\n",
      "{\n",
      "    \"prompt\": {\n",
      "        \"name\": \"ExamplePrompt\",\n",
      "        \"description\": \"A prompt that uses context to ground an incoming question\",\n",
      "        \"authors\": [\n",
      "            \"Mutaz\"\n",
      "        ],\n",
      "        \"tags\": [],\n",
      "        \"version\": \"\",\n",
      "        \"base\": \"\",\n",
      "        \"basePrompty\": \"None\",\n",
      "        \"model\": {\n",
      "            \"api\": \"chat\",\n",
      "            \"configuration\": {\n",
      "                \"type\": \"azure_openai\",\n",
      "                \"azure_deployment\": \"o3-mini\",\n",
      "                \"api_key\": \"**********\",\n",
      "                \"api_version\": \"2024-05-01-preview\",\n",
      "                \"azure_endpoint\": \"2024-12-01-preview\"\n",
      "            },\n",
      "            \"parameters\": {\n",
      "                \"max_tokens\": 3000,\n",
      "                \"temperature\": 0.5\n",
      "            },\n",
      "            \"response\": {}\n",
      "        },\n",
      "        \"sample\": {\n",
      "            \"firstName\": \"Ali\",\n",
      "            \"additional_context\": \"the  customer who is looking for information about new advanced AI models\",\n",
      "            \"question\": \"What can you tell me about latest AI models?\",\n",
      "            \"chat_history\": [\n",
      "                {\n",
      "                    \"role\": \"user\",\n",
      "                    \"content\": \"what's the capital of France?\"\n",
      "                },\n",
      "                {\n",
      "                    \"role\": \"assistant\",\n",
      "                    \"content\": \"Paris\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"inputs\": {\n",
      "            \"firstName\": {\n",
      "                \"type\": \"string\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            },\n",
      "            \"additional_context\": {\n",
      "                \"type\": \"string\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            },\n",
      "            \"question\": {\n",
      "                \"type\": \"string\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            },\n",
      "            \"chat_history\": {\n",
      "                \"type\": \"list\",\n",
      "                \"default\": \"None\",\n",
      "                \"description\": \"\"\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {},\n",
      "        \"template\": {\n",
      "            \"type\": \"jinja2\",\n",
      "            \"parser\": \"prompty\"\n",
      "        },\n",
      "        \"file\": \"c:\\\\git\\\\misc\\\\prompty\\\\promptyfiles\\\\aoai_basic_o3mini.prompty\",\n",
      "        \"content\": \"system:\\nYou are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping {{firstName}} to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to {{firstName}}:\\n{{additional_context}}\\n\\nuser:\\n{{question}}\\n\"\n",
      "    },\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"You are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"What is the capital of France?\"\n",
      "        }\n",
      "    ],\n",
      "    \"configuration\": {},\n",
      "    \"parameters\": {},\n",
      "    \"raw\": false\n",
      "}\n",
      "Starting AzureOpenAIExecutor\n",
      "signature:\n",
      "\"prompty.azure.executor.AzureOpenAIExecutor.invoke\"\n",
      "inputs:\n",
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"You are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"What is the capital of France?\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Starting AzureOpenAI\n",
      "type:\n",
      "\"LLM\"\n",
      "signature:\n",
      "\"AzureOpenAI.ctor\"\n",
      "description:\n",
      "\"Azure OpenAI Constructor\"\n",
      "inputs:\n",
      "{\n",
      "    \"azure_deployment\": \"o3-mini\",\n",
      "    \"api_key\": \"**********\",\n",
      "    \"api_version\": \"2024-05-01-preview\",\n",
      "    \"azure_endpoint\": \"2024-12-01-preview\"\n",
      "}\n",
      "result:\n",
      "\"<openai.lib.azure.AzureOpenAI object at 0x000002B5F7947C70>\"\n",
      "Ending AzureOpenAI\n",
      "Starting create\n",
      "type:\n",
      "\"LLM\"\n",
      "description:\n",
      "\"Azure OpenAI Client\"\n",
      "signature:\n",
      "\"AzureOpenAI.chat.completions.create\"\n",
      "inputs:\n",
      "{\n",
      "    \"model\": \"o3-mini\",\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"You are an AI assistant who helps people find information. As the assistant,\\nyou answer questions briefly, succinctly, and in a personable manner using\\nmarkdown and even add some personal flair with appropriate emojis.\\n\\nYou always respond in Arabic only.\\n# Customer\\nYou are helping Ali to find answers to their questions.\\nUse their name to address them in your responses.\\n\\n# Context\\nUse the following context to provide a more personalized response to Ali:\\nthe  customer who is looking for information about new advanced AI models\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"What is the capital of France?\"\n",
      "        }\n",
      "    ],\n",
      "    \"max_tokens\": 3000,\n",
      "    \"temperature\": 0.5\n",
      "}\n",
      "Ending create\n",
      "result:\n",
      "{\n",
      "    \"exception\": {\n",
      "        \"type\": \"<class 'openai.APIConnectionError'>\",\n",
      "        \"traceback\": [\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 170, in wrapper\\n    result = func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 71, in run\\n    return self.invoke(data)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\azure\\\\executor.py\\\", line 100, in invoke\\n    raw = client.chat.completions.with_raw_response.create(**args)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_legacy_response.py\\\", line 364, in wrapped\\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_utils\\\\_utils.py\\\", line 279, in wrapper\\n    return func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\resources\\\\chat\\\\completions\\\\completions.py\\\", line 914, in create\\n    return self._post(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1242, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 919, in request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 979, in _request\\n    return self._retry_request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1057, in _retry_request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 979, in _request\\n    return self._retry_request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1057, in _retry_request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 989, in _request\\n    raise APIConnectionError(request=request) from err\\n\"\n",
      "        ],\n",
      "        \"message\": \"Connection error.\",\n",
      "        \"args\": \"('Connection error.',)\"\n",
      "    }\n",
      "}\n",
      "Ending AzureOpenAIExecutor\n",
      "result:\n",
      "{\n",
      "    \"exception\": {\n",
      "        \"type\": \"<class 'openai.APIConnectionError'>\",\n",
      "        \"traceback\": [\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 170, in wrapper\\n    result = func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\__init__.py\\\", line 429, in run\\n    result = InvokerFactory.run_executor(prompt, content)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 267, in run_executor\\n    return cls.run(\\\"executor\\\", prompty, data, default)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 219, in run\\n    value = invoker.run(data)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 188, in wrapper\\n    raise e\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 170, in wrapper\\n    result = func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 71, in run\\n    return self.invoke(data)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\azure\\\\executor.py\\\", line 100, in invoke\\n    raw = client.chat.completions.with_raw_response.create(**args)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_legacy_response.py\\\", line 364, in wrapped\\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_utils\\\\_utils.py\\\", line 279, in wrapper\\n    return func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\resources\\\\chat\\\\completions\\\\completions.py\\\", line 914, in create\\n    return self._post(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1242, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 919, in request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 979, in _request\\n    return self._retry_request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1057, in _retry_request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 979, in _request\\n    return self._retry_request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1057, in _retry_request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 989, in _request\\n    raise APIConnectionError(request=request) from err\\n\"\n",
      "        ],\n",
      "        \"message\": \"Connection error.\",\n",
      "        \"args\": \"('Connection error.',)\"\n",
      "    }\n",
      "}\n",
      "Ending run\n",
      "result:\n",
      "{\n",
      "    \"exception\": {\n",
      "        \"type\": \"<class 'openai.APIConnectionError'>\",\n",
      "        \"traceback\": [\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 170, in wrapper\\n    result = func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\__init__.py\\\", line 537, in execute\\n    result = run(prompt, content, configuration, parameters, raw)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 188, in wrapper\\n    raise e\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 170, in wrapper\\n    result = func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\__init__.py\\\", line 429, in run\\n    result = InvokerFactory.run_executor(prompt, content)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 267, in run_executor\\n    return cls.run(\\\"executor\\\", prompty, data, default)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 219, in run\\n    value = invoker.run(data)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 188, in wrapper\\n    raise e\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\tracer.py\\\", line 170, in wrapper\\n    result = func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\invoker.py\\\", line 71, in run\\n    return self.invoke(data)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\prompty\\\\azure\\\\executor.py\\\", line 100, in invoke\\n    raw = client.chat.completions.with_raw_response.create(**args)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_legacy_response.py\\\", line 364, in wrapped\\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_utils\\\\_utils.py\\\", line 279, in wrapper\\n    return func(*args, **kwargs)\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\resources\\\\chat\\\\completions\\\\completions.py\\\", line 914, in create\\n    return self._post(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1242, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 919, in request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 979, in _request\\n    return self._retry_request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1057, in _retry_request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 979, in _request\\n    return self._retry_request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 1057, in _retry_request\\n    return self._request(\\n\",\n",
      "            \"  File \\\"c:\\\\git\\\\misc\\\\prompty\\\\.venv\\\\lib\\\\site-packages\\\\openai\\\\_base_client.py\\\", line 989, in _request\\n    raise APIConnectionError(request=request) from err\\n\"\n",
      "        ],\n",
      "        \"message\": \"Connection error.\",\n",
      "        \"args\": \"('Connection error.',)\"\n",
      "    }\n",
      "}\n",
      "Ending execute\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:207\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedProtocol(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest URL is missing an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m protocol.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mws\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwss\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    956\u001b[0m         request,\n\u001b[0;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[1;32mC:\\python\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:207\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedProtocol(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest URL is missing an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m protocol.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mws\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwss\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    956\u001b[0m         request,\n\u001b[0;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[1;32mC:\\python\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:207\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedProtocol(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest URL is missing an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m protocol.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mws\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwss\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    956\u001b[0m         request,\n\u001b[0;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[1;32mC:\\python\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\n\u001b[0;32m      2\u001b[0m         question: \u001b[38;5;28many\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of France?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mprompty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/promptyfiles/aoai_basic_o3mini.prompty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirstname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJohn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(result)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\tracer.py:188\u001b[0m, in \u001b[0;36m_trace_sync.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    173\u001b[0m     trace(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m         },\n\u001b[0;32m    187\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\tracer.py:170\u001b[0m, in \u001b[0;36m_trace_sync.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    171\u001b[0m     trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, _results(result))\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\__init__.py:537\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(prompt, configuration, parameters, inputs, raw, config_name)\u001b[0m\n\u001b[0;32m    534\u001b[0m content \u001b[38;5;241m=\u001b[39m prepare(prompt, inputs)\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# run LLM model\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\tracer.py:188\u001b[0m, in \u001b[0;36m_trace_sync.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    173\u001b[0m     trace(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m         },\n\u001b[0;32m    187\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\tracer.py:170\u001b[0m, in \u001b[0;36m_trace_sync.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    171\u001b[0m     trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, _results(result))\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\__init__.py:429\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(prompt, content, configuration, parameters, raw)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;241m!=\u001b[39m {}:\n\u001b[0;32m    427\u001b[0m     prompt\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m param_hoisting(parameters, prompt\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[1;32m--> 429\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mInvokerFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[0;32m    431\u001b[0m     result \u001b[38;5;241m=\u001b[39m InvokerFactory\u001b[38;5;241m.\u001b[39mrun_processor(prompt, result)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\invoker.py:267\u001b[0m, in \u001b[0;36mInvokerFactory.run_executor\u001b[1;34m(cls, prompty, data, default)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_executor\u001b[39m(\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mcls\u001b[39m, prompty: Prompty, data: typing\u001b[38;5;241m.\u001b[39mAny, default: typing\u001b[38;5;241m.\u001b[39mAny \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecutor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\invoker.py:219\u001b[0m, in \u001b[0;36mInvokerFactory.run\u001b[1;34m(cls, type, prompty, data, default)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m    218\u001b[0m invoker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_invoker(\u001b[38;5;28mtype\u001b[39m, prompty)\n\u001b[1;32m--> 219\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43minvoker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\tracer.py:188\u001b[0m, in \u001b[0;36m_trace_sync.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    173\u001b[0m     trace(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m         },\n\u001b[0;32m    187\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\tracer.py:170\u001b[0m, in \u001b[0;36m_trace_sync.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    171\u001b[0m     trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, _results(result))\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\invoker.py:71\u001b[0m, in \u001b[0;36mInvoker.run\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@trace\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method to run the invoker\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m        The invoked\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\prompty\\azure\\executor.py:100\u001b[0m, in \u001b[0;36mAzureOpenAIExecutor.invoke\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     98\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     raw \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    102\u001b[0m     response \u001b[38;5;241m=\u001b[39m ChatCompletion\u001b[38;5;241m.\u001b[39mmodel_validate_json(raw\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m raw\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mraw:\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\misc\\prompty\\.venv\\lib\\site-packages\\openai\\_base_client.py:989\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    980\u001b[0m             input_options,\n\u001b[0;32m    981\u001b[0m             cast_to,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    985\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m         )\n\u001b[0;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    993\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    998\u001b[0m )\n\u001b[0;32m    999\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519fb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
